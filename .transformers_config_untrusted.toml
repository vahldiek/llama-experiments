
#ID or path of the base LLM to load
llm_model_id = "meta-llama/Llama-3.1-8B-Instruct"

#Path to the Intel quantized model
#quantized_model_path = "../models/Llama-2-13b-chat-hf-int8.pt"

#Set to true to use GPU with the model.  If true, the quantized model will not be used
use_GPU = false

#The title of the chat web page
chat_page_name2 = "Protected by Intel® TDX"

chat_page_name = "Llama 3.1 8B on Intel® Xeon®"

#System prompt sent to the LLM with each query
llm_system_prompt = '''
Your responses should be professional and succinct.  Respond with no more than 2 or 3 short sentences. You are the 8 billion parameter LLama AI agent running on an Intel Xeon processor.  Always answer in 2 or 3 sentences.
'''

#If true, the LLM will use conversation history, if false, it will
#only answer one question at a time
use_conversation_history = false

#Maximum number of response tokens the LLM is allowed to return before
#stopping
max_response_tokens = 500

#Maximum number of tokens to send to LLM.  If tokens becomes larger
#than this, older rounds of the conversation are pruned off.
max_prompt_tokens = 2000

#If true, use RAG in chat queries
use_RAG = true

#If true, always asks for concise responses even if no relevant data
#found in vector store.  If false, provides no guidance with the prompt, just sends the
#prompt that the user typed in
always_use_RAG_prompt = false

rag_prompt_template = '''
Use the following pieces of context to provide a brief 2 or 3 sentence answer to the question at the end.  If you don't know the answer, say that you don't know,
do not try to make up an answer.  Your answer should be 2 or 3 sentences.
Always say "thanks for asking!" at the end of the answer.
Context: {context}
Question: "{question}"
Helpful Answer:'''

#Files to process and integrate into a RAG search with the query
#rag_file_dir = "./limited_rag_documents"
rag_file_dir = "./untrusted_rag_documents"
#rag_file_dir = "./expansive_rag_documents"

#Directory to store the persistent Chroma DB
rag_db_dir = "./chroma_db/*"

#vector store matches must have at least this relevance score,
#between 0 and 1
rag_relevance_limit = 0.5

#Maximum number of characters when splitting docs for RAG
rag_doc_max_chars = 800

#Maximum number of RAG documents to include in prompt
max_rag_documents = 2

#If true, reset the contents of the RAG database every time the
#Python script is launched.  If use_RAG is false, this parameter
#has no effect.
reset_RAG_db = true

#If true, rescan the files in the directory every time the
#Python script is launched.  If this parameter is true and
#reset_RAG_db is false, only documents newly added to the
#directory since the last time the database was built will
#be added.  If reset_RAG_db is true, all documents will be
#scanned again.  If use_RAG is false, this parameter has no
#effect.
rescan_RAG_files = true
